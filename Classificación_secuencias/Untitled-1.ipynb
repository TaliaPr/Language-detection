{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdc86757",
   "metadata": {},
   "source": [
    "# A Jupyter Notebook with Type Annotations for Named Entity Recognition (NER)\n",
    "\n",
    "This notebook demonstrates how to implement type annotations for all code related to Named Entity Recognition (NER). Type annotations improve code readability, maintainability, and debugging by explicitly specifying the expected types of variables, function parameters, and return values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f042b1",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries with Type Annotations\n",
    "\n",
    "Add type annotations for imported libraries and modules, ensuring clarity on their usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2465e7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries with Type Annotations\n",
    "from typing import List, Tuple, Dict, Any, Optional\n",
    "import nltk\n",
    "from nltk.corpus import conll2002\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "from nltk.tag import CRFTagger\n",
    "from itertools import combinations\n",
    "import time\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b7ae8d",
   "metadata": {},
   "source": [
    "## 2. Load and Prepare Data with Type Annotations\n",
    "\n",
    "Include type annotations for variables and functions used to load and prepare the conll2002 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4cf2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and Prepare Data with Type Annotations\n",
    "def load_data() -> Tuple[List[List[Tuple[str, str, str]]], List[List[Tuple[str, str, str]]]]:\n",
    "    \"\"\"\n",
    "    Load the Spanish NER data from the conll2002 corpus.\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing the training and test datasets.\n",
    "    \"\"\"\n",
    "    train: List[List[Tuple[str, str, str]]] = conll2002.iob_sents('esp.train')\n",
    "    test: List[List[Tuple[str, str, str]]] = conll2002.iob_sents('esp.testb')\n",
    "    return train, test\n",
    "\n",
    "# Load the data\n",
    "train_data, test_data = load_data()\n",
    "\n",
    "print(f\"Training set: {len(train_data)} sentences\")\n",
    "print(f\"Test set: {len(test_data)} sentences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153cbc44",
   "metadata": {},
   "source": [
    "## 3. Process Data Using Custom Classes with Type Annotations\n",
    "\n",
    "Add type annotations to the custom data processing class and its methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c733f016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process Data Using Custom Classes with Type Annotations\n",
    "class DataProcessor:\n",
    "    def __init__(self, sentence: List[Tuple[str, str, str]]) -> None:\n",
    "        self.sentence = sentence\n",
    "\n",
    "    def get_words(self) -> List[str]:\n",
    "        return [word for word, _, _ in self.sentence]\n",
    "\n",
    "    def get_pos_tags(self) -> List[str]:\n",
    "        return [pos for _, pos, _ in self.sentence]\n",
    "\n",
    "    def get_bio_tags(self) -> List[str]:\n",
    "        return [bio for _, _, bio in self.sentence]\n",
    "\n",
    "# Example usage\n",
    "processor = DataProcessor(train_data[0])\n",
    "print(\"Words:\", processor.get_words())\n",
    "print(\"POS Tags:\", processor.get_pos_tags())\n",
    "print(\"BIO Tags:\", processor.get_bio_tags())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e21b0a",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering for NER with Type Annotations\n",
    "\n",
    "Implement type annotations for the `OptimizedFeatFunc` class and its methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d01967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering for NER with Type Annotations\n",
    "class OptimizedFeatFunc:\n",
    "    def __init__(\n",
    "        self,\n",
    "        use_basic: bool = True,\n",
    "        use_context_words: bool = True,\n",
    "        use_context_pos_tags: bool = True,\n",
    "        use_specific_characteristics: bool = True,\n",
    "        use_lemmas: bool = True\n",
    "    ) -> None:\n",
    "        self.use_basic = use_basic\n",
    "        self.use_context_words = use_context_words\n",
    "        self.use_context_pos_tags = use_context_pos_tags\n",
    "        self.use_specific_characteristics = use_specific_characteristics\n",
    "        self.use_lemmas = use_lemmas\n",
    "\n",
    "    def __call__(self, tokens: List[Tuple[str, str, str]], idx: int) -> Dict[str, Any]:\n",
    "        features: Dict[str, Any] = {}\n",
    "        if idx < 0 or idx >= len(tokens):\n",
    "            return features\n",
    "\n",
    "        word, pos, lemma = tokens[idx]\n",
    "        if self.use_basic:\n",
    "            features[\"word\"] = word\n",
    "            features[\"length\"] = len(word)\n",
    "        if self.use_context_words and idx > 0:\n",
    "            features[\"prev_word\"] = tokens[idx - 1][0]\n",
    "        if self.use_context_pos_tags:\n",
    "            features[\"pos\"] = pos\n",
    "        if self.use_lemmas:\n",
    "            features[\"lemma\"] = lemma\n",
    "        return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefbab5c",
   "metadata": {},
   "source": [
    "## 5. Prepare Data for CRF Model with Type Annotations\n",
    "\n",
    "Add type annotations to the `prepare_data_for_crf` function and its parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8168fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Data for CRF Model with Type Annotations\n",
    "def prepare_data_for_crf(\n",
    "    conll_data: List[List[Tuple[str, str, str]]],\n",
    "    include_lemmas: bool = True\n",
    ") -> List[List[Tuple[Tuple[str, str, str], str]]]:\n",
    "    \"\"\"\n",
    "    Process conll data into format for CRF tagging with optional lemmatization.\n",
    "\n",
    "    Args:\n",
    "        conll_data: The input data in conll format.\n",
    "        include_lemmas: Whether to include lemmas in the processed data.\n",
    "\n",
    "    Returns:\n",
    "        The processed data formatted for CRF tagging.\n",
    "    \"\"\"\n",
    "    processed_data: List[List[Tuple[Tuple[str, str, str], str]]] = []\n",
    "    for sentence in conll_data:\n",
    "        processed_sentence: List[Tuple[Tuple[str, str, str], str]] = [\n",
    "            ((word, pos, word.lower()), tag) for word, pos, tag in sentence\n",
    "        ]\n",
    "        processed_data.append(processed_sentence)\n",
    "    return processed_data\n",
    "\n",
    "# Process the training data\n",
    "processed_train_data = prepare_data_for_crf(train_data)\n",
    "print(\"Processed training data example:\", processed_train_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9b6800",
   "metadata": {},
   "source": [
    "## 6. Train a CRF Model for NER with Type Annotations\n",
    "\n",
    "Include type annotations for the CRF model training process and related functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685e39af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a CRF Model for NER with Type Annotations\n",
    "def train_crf_model(\n",
    "    train_data: List[List[Tuple[Tuple[str, str, str], str]]],\n",
    "    model_path: str\n",
    ") -> CRFTagger:\n",
    "    \"\"\"\n",
    "    Train a CRF model for NER.\n",
    "\n",
    "    Args:\n",
    "        train_data: The training data formatted for CRF tagging.\n",
    "        model_path: The path to save the trained model.\n",
    "\n",
    "    Returns:\n",
    "        The trained CRFTagger instance.\n",
    "    \"\"\"\n",
    "    crf_tagger = CRFTagger()\n",
    "    crf_tagger.train(train_data, model_path)\n",
    "    return crf_tagger\n",
    "\n",
    "# Train the model\n",
    "model_path = \"ner_model.crf.tagger\"\n",
    "trained_crf_model = train_crf_model(processed_train_data, model_path)\n",
    "print(\"CRF model trained and saved to:\", model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67661b7",
   "metadata": {},
   "source": [
    "## 7. Experiment with Different Tag Encoding Schemes with Type Annotations\n",
    "\n",
    "Add type annotations to functions for converting between tagging schemes (BIO, IO, BIOES)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890956ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment with Different Tag Encoding Schemes with Type Annotations\n",
    "def bio_to_io(tagged_sentence: List[Tuple[str, str]]) -> List[Tuple[str, str]]:\n",
    "    \"\"\"\n",
    "    Convert BIO tagging to IO tagging.\n",
    "\n",
    "    Args:\n",
    "        tagged_sentence: A list of tuples containing words and BIO tags.\n",
    "\n",
    "    Returns:\n",
    "        A list of tuples with IO tags.\n",
    "    \"\"\"\n",
    "    io_sentence: List[Tuple[str, str]] = []\n",
    "    for word, tag in tagged_sentence:\n",
    "        if tag.startswith(\"B-\"):\n",
    "            io_sentence.append((word, \"I-\" + tag[2:]))\n",
    "        else:\n",
    "            io_sentence.append((word, tag))\n",
    "    return io_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db42fee",
   "metadata": {},
   "source": [
    "## 8. Entity-Level Evaluation with Type Annotations\n",
    "\n",
    "Implement type annotations for entity extraction, evaluation, and corpus-level evaluation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe45ec00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entity-Level Evaluation with Type Annotations\n",
    "def extract_entities(tags: List[str]) -> List[Tuple[str, int, int]]:\n",
    "    \"\"\"\n",
    "    Extract entity spans from a sequence of BIO tags.\n",
    "\n",
    "    Args:\n",
    "        tags: List of BIO tags.\n",
    "\n",
    "    Returns:\n",
    "        List of tuples (entity_type, start_idx, end_idx).\n",
    "    \"\"\"\n",
    "    entities: List[Tuple[str, int, int]] = []\n",
    "    entity_type: Optional[str] = None\n",
    "    start_idx: Optional[int] = None\n",
    "\n",
    "    for i, tag in enumerate(tags):\n",
    "        if tag.startswith(\"B-\"):\n",
    "            if entity_type is not None:\n",
    "                entities.append((entity_type, start_idx, i - 1))\n",
    "            entity_type = tag[2:]\n",
    "            start_idx = i\n",
    "        elif tag == \"O\" and entity_type is not None:\n",
    "            entities.append((entity_type, start_idx, i - 1))\n",
    "            entity_type = None\n",
    "            start_idx = None\n",
    "\n",
    "    if entity_type is not None:\n",
    "        entities.append((entity_type, start_idx, len(tags) - 1))\n",
    "    return entities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7ec69e",
   "metadata": {},
   "source": [
    "## 9. Feature Combination Analysis with Type Annotations\n",
    "\n",
    "Add type annotations to functions for evaluating feature combinations and selecting the best configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81992298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Combination Analysis with Type Annotations\n",
    "def evaluate_feature_combination(\n",
    "    config: Dict[str, bool],\n",
    "    train_data: List[List[Tuple[Tuple[str, str, str], str]]],\n",
    "    test_data: List[List[Tuple[Tuple[str, str, str], str]]]\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Evaluate a feature combination for NER.\n",
    "\n",
    "    Args:\n",
    "        config: A dictionary specifying which features to use.\n",
    "        train_data: The training data formatted for CRF tagging.\n",
    "        test_data: The test data formatted for CRF tagging.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary with evaluation metrics (precision, recall, F1).\n",
    "    \"\"\"\n",
    "    feat_func = OptimizedFeatFunc(\n",
    "        use_basic=config[\"Basic\"],\n",
    "        use_context_words=config[\"Context_Words\"],\n",
    "        use_context_pos_tags=config[\"Context_POS\"],\n",
    "        use_specific_characteristics=config[\"Specific\"],\n",
    "        use_lemmas=config[\"Lemmas\"]\n",
    "    )\n",
    "    crf_tagger = CRFTagger(feature_func=feat_func)\n",
    "    crf_tagger.train(train_data, \"temp_model.crf.tagger\")\n",
    "    # Placeholder for evaluation logic\n",
    "    return {\"precision\": 0.0, \"recall\": 0.0, \"f1\": 0.0}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abf6ee8",
   "metadata": {},
   "source": [
    "## 10. Full Analysis with Optimized Features with Type Annotations\n",
    "\n",
    "Include type annotations for the complete analysis process using the optimal feature configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9f9515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full Analysis with Optimized Features with Type Annotations\n",
    "def run_full_analysis(\n",
    "    train_data: List[List[Tuple[Tuple[str, str, str], str]]],\n",
    "    test_data: List[List[Tuple[Tuple[str, str, str], str]]]\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Run a full analysis using the optimal feature configuration.\n",
    "\n",
    "    Args:\n",
    "        train_data: The training data formatted for CRF tagging.\n",
    "        test_data: The test data formatted for CRF tagging.\n",
    "    \"\"\"\n",
    "    optimal_config = {\n",
    "        \"Basic\": True,\n",
    "        \"Context_Words\": True,\n",
    "        \"Context_POS\": True,\n",
    "        \"Specific\": True,\n",
    "        \"Lemmas\": True\n",
    "    }\n",
    "    metrics = evaluate_feature_combination(optimal_config, train_data, test_data)\n",
    "    print(\"Optimal Configuration Metrics:\", metrics)\n",
    "\n",
    "# Run the full analysis\n",
    "run_full_analysis(processed_train_data, prepare_data_for_crf(test_data))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
