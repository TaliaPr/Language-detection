{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1815ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of running a complete analysis with the optimal feature configuration\n",
    "def run_optimal_configuration(model_path=None, preprocessed_test=None, train_tags=None):\n",
    "    \"\"\"\n",
    "    Run a complete analysis with the optimal feature configuration.\n",
    "    \n",
    "    Args:\n",
    "        model_path: Optional path to a pre-trained model file. If provided, the model will be loaded\n",
    "                   instead of being trained.\n",
    "        preprocessed_test: Test data for evaluation.\n",
    "        train_tags: If provided, this is used as the tagging scheme for entity extraction.\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with evaluation results.\n",
    "    \"\"\"\n",
    "    # Create feature function with optimal settings\n",
    "    optimal_feat_func = OptimizedFeatFunc(\n",
    "        use_Basic=True,\n",
    "        use_context_words=True, \n",
    "        use_contex_POS_tag=True,\n",
    "        use_lemas=True,\n",
    "        use_specific_caracteristics=True\n",
    "    )\n",
    "    \n",
    "    # Initialize CRF tagger with our feature function\n",
    "    optimal_tagger = CRFTagger(feature_func=optimal_feat_func)\n",
    "    \n",
    "    # Load the pre-trained model\n",
    "    if model_path:\n",
    "        print(f\"Loading pre-trained model from {model_path}...\")\n",
    "        optimal_tagger.set_model_file(model_path)\n",
    "    \n",
    "    print(\"Evaluating model on test data...\")\n",
    "    \n",
    "    # Determine which tagging scheme to use for evaluation\n",
    "    tagging_scheme = None\n",
    "    if isinstance(train_tags, str):  # If train_tags is a string (tag scheme name)\n",
    "        tagging_scheme = train_tags\n",
    "    \n",
    "    # Evaluate using entity-level metrics\n",
    "    entity_results = entity_level_accuracy(optimal_tagger, preprocessed_test, otherTAG=tagging_scheme)\n",
    "    \n",
    "    print(\"\\n=== Entity-Level Evaluation Results ===\")\n",
    "    print(f\"Precision: {entity_results['precision']:.4f}\")\n",
    "    print(f\"Recall: {entity_results['recall']:.4f}\")\n",
    "    print(f\"F1 Score: {entity_results['f1']:.4f}\")\n",
    "\n",
    "    # Create and display confusion matrix\n",
    "    print(\"\\n=== Entity-Level Confusion Matrix ===\")\n",
    "    plot_confusion_matrix(entity_results['confusion_matrix'], entity_results['entity_types'])\n",
    "    \n",
    "    return entity_results\n",
    "\n",
    "# Example usage:\n",
    "# To load the pre-trained best model:\n",
    "best_model_path = 'best_model_r4_B_C_C_L.crf.tagger'\n",
    "# results = run_optimal_configuration(model_path=best_model_path, preprocessed_test=preprocessed_test)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
