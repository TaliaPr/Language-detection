{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.collocations import TrigramCollocationFinder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_train(text):\n",
    "    text = text.lower() \n",
    "    text = re.sub(' {2}', ' ', text)\n",
    "    text = re.sub(r'\\n', '  ', text)\n",
    "    text = re.sub(r'[\\d%,)•($:]', '', text)             \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_parameters(text):\n",
    "    finder = TrigramCollocationFinder.from_words(text)\n",
    "    dic = {}# Las ci ocurrencias del trigrama es el valor en el diccionario\n",
    "    N = 0\n",
    "    for k, v in finder.ngram_fd.items(): # N supongo qu es la suma de todos los valores de las claves del diccionario \n",
    "        if v > 5:\n",
    "            dic[k] = v\n",
    "        N += v\n",
    "    B = len(dic)\n",
    "    return [B, N, dic]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "\n",
    "def lindstone(sentence, c_train, B_train, N_train):\n",
    "    lamda = 0.05\n",
    "    prob_acum = 0\n",
    "    finder = TrigramCollocationFinder.from_words(sentence)\n",
    "\n",
    "    for n in finder.ngram_fd.items():\n",
    "        grama = n[0]\n",
    "        freq = c_train[grama]\n",
    "        prob_acum += log(freq + lamda) / (N_train + B_train * lamda)\n",
    "    return prob_acum\n",
    "\n",
    "############# hay que desacer el log posteriormente?\n",
    "############# tenemos que comprobar todos los tests con todos los train de todos los idiomas? SÍ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "Param_lang = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(l1, l2):\n",
    "    #l1 lista de srings de nombres de ficheros (o direcciones donde se encuentra el fichero, tambien str)\n",
    "    # l2 lista de nombres de idioma a la que pertenece cada fichero\n",
    "    # len(l1) == len(l2)\n",
    "    for i in range(len(l1)):\n",
    "        with open(l1[i], 'r', encoding='utf-8') as f:\n",
    "            raw_text = f.read()\n",
    "        prep_text = preprocess_train(raw_text)\n",
    "        Param_lang[l2[i]] = find_parameters(prep_text)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test_files):\n",
    "    #test_files lista de strings de fichero de test\n",
    "    Files_classified = [None]*len(test_files)\n",
    "    \n",
    "    for t in range(len(test_files)):\n",
    "        with open(test_files[t], 'r', encoding='utf-8') as f:\n",
    "            raw_test = f.read()\n",
    "\n",
    "        prep_test = preproces_test(raw_test)\n",
    "        sentences = prep_test.split(\"  \") #suponiendo que funciona que cada oracion esta separada por solo 2 espacios\n",
    "        D_answer = {}\n",
    "        Answer = [None]*len(sentences)\n",
    "        for s in range(len(sentences)):\n",
    "            for k in Param_lang.keys():\n",
    "                l = Param_lang[k]\n",
    "                B = l[0]\n",
    "                N = l[1]\n",
    "                c = l[2]\n",
    "                prob = lindstone(sentences[s], c, B, N)\n",
    "                D_answer[k] = prob\n",
    "            Answer[s] = max(D_answer, key=D_answer.get)\n",
    "        Files_classified[t] = Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = ['eng_trn.txt', 'spa_trn.txt', 'fra_trn.txt', 'ita_trn.txt', 'deu_trn.txt']\n",
    "lang_of_train_f = ['eng', 'spa', 'fra', 'ita', 'deu']\n",
    "train(train_files, lang_of_train_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files =['eng_tst.txt', 'ita_tst.txt', 'fra_tst.txt', 'spa_tst.txt', 'deu_tst.txt']\n",
    "Class_matrix = predict(test_files)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
